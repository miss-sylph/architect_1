{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNH5bvBKaad+gOKUOAJYd7l"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Задание 2\n","\n","Генерация синтетических данных с использованием Apache Spark\n","Цель задания: Использовать Apache Spark для создания синтетического набора данных, который имитирует информацию о покупках в интернет-магазине. Набор данных должен включать в себя информацию о заказах, включая дату заказа, идентификатор пользователя, название товара, количество и цену. Сгенерированные данные будут использованы для последующего анализа покупательской активности и понимания потребительских трендов.\n","\n","Шаги выполнения:\n","Генерация данных:\n","\n","Создать DataFrame с полями: Дата, UserID, Продукт, Количество, Цена.\n","\n","Данные для поля Продукт генерируются из списка возможных товаров ( не меньше 5 товаров )\n","\n","Количество и Цена должны генерироваться случайно в заданных пределах.\n","\n","Дата должна быть в пределах последнего года.\n","\n","UserID представляет собой случайное число, имитирующее идентификаторы пользователей.\n","\n","Обратите внимание, что должна быть возможности изменять количество сгенерированных строк. Минимальное количество - 1000 строк.\n","\n","Сохранение данных:\n","\n","Сохранить сгенерированный DataFrame в формате CSV для последующего анализа.\n","\n","Результат выполнения задания (код генерации синтетических данных и созданный файл *.csv) необходимо выложить в github/gitlab и указать ссылку на Ваш репозиторий (не забудьте: репозиторий должен быть публичным)."],"metadata":{"id":"_PvgRWU1mXgw"}},{"cell_type":"code","source":["pip install pyspark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jeHvJIXamWEm","executionInfo":{"status":"ok","timestamp":1732442218650,"user_tz":-600,"elapsed":4047,"user":{"displayName":"Екатерина Подрезова","userId":"12202472461904248563"}},"outputId":"35cd259b-8605-41b3-de9c-209b36136eaa"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"]}]},{"cell_type":"code","source":["pip install install-jdk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"onpyiiJRmncn","executionInfo":{"status":"ok","timestamp":1732442231103,"user_tz":-600,"elapsed":3957,"user":{"displayName":"Екатерина Подрезова","userId":"12202472461904248563"}},"outputId":"f93ff578-b0e3-4b83-9482-5da966fc53a7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting install-jdk\n","  Downloading install_jdk-1.1.0-py3-none-any.whl.metadata (12 kB)\n","Downloading install_jdk-1.1.0-py3-none-any.whl (15 kB)\n","Installing collected packages: install-jdk\n","Successfully installed install-jdk-1.1.0\n"]}]},{"cell_type":"code","source":["pip install findspark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T6Oqi9Kxmqse","executionInfo":{"status":"ok","timestamp":1732442245340,"user_tz":-600,"elapsed":3959,"user":{"displayName":"Екатерина Подрезова","userId":"12202472461904248563"}},"outputId":"3fa9a4bd-69fd-4a57-de4b-7763c892c515"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting findspark\n","  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n","Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n","Installing collected packages: findspark\n","Successfully installed findspark-2.0.1\n"]}]},{"cell_type":"code","source":["import random\n","from datetime import datetime, timedelta\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col\n","import pandas as pd\n","\n","# Инициализация SparkSession\n","spark = SparkSession.builder.master(\"local\").appName(\"Purchase Data Generation\").getOrCreate()\n","\n","# Список возможных товаров\n","products = [\"Laptop\", \"Smartphone\", \"Headphones\", \"Tablet\", \"Smartwatch\"]\n","\n","# Функция для генерации случайной даты в прошлом году\n","def generate_random_date():\n","    end_date = datetime.now()\n","    start_date = end_date - timedelta(days=365)\n","    random_date = start_date + (end_date - start_date) * random.random()\n","    return random_date.strftime(\"%Y-%m-%d\")\n","\n","# Генерация данных\n","data = []\n","num_records = 1000  # количество строк, можно изменить\n","\n","for _ in range(num_records):\n","    date = generate_random_date()\n","    user_id = random.randint(1, 500)  # случайный UserID от 1 до 500\n","    product = random.choice(products)  # случайный товар\n","    quantity = random.randint(1, 10)  # количество от 1 до 10\n","    price = round(random.uniform(10, 1000), 2)  # цена от 10 до 1000\n","    data.append((date, user_id, product, quantity, price))\n","\n","# Создание DataFrame с помощью PySpark\n","columns = [\"Дата\", \"UserID\", \"Продукт\", \"Количество\", \"Цена\"]\n","df = spark.createDataFrame(data, columns)\n","\n","# Показать первые несколько строк данных\n","df.show(5)\n","\n","# Преобразуем в Pandas DataFrame для удобства сохранения в CSV\n","pdf = df.toPandas()\n","\n","# Сохранение в CSV\n","output_file = \"output_data.csv\"\n","pdf.to_csv(output_file, index=False)\n","\n","print(f\"Данные сохранены в файл {output_file}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UN8xFbTmnDE2","executionInfo":{"status":"ok","timestamp":1732442650353,"user_tz":-600,"elapsed":1405,"user":{"displayName":"Екатерина Подрезова","userId":"12202472461904248563"}},"outputId":"9527787c-737d-4208-d5c4-1193a5641825"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------+----------+----------+------+\n","|      Дата|UserID|   Продукт|Количество|  Цена|\n","+----------+------+----------+----------+------+\n","|2024-01-01|   488|Smartwatch|         3|305.14|\n","|2024-04-24|   106|    Tablet|         4|399.27|\n","|2024-11-03|   436|Smartwatch|         5|412.36|\n","|2024-07-03|   369|Smartwatch|         9| 791.2|\n","|2023-11-27|   188|Headphones|         3|243.16|\n","+----------+------+----------+----------+------+\n","only showing top 5 rows\n","\n","Данные сохранены в файл output_data.csv\n"]}]}]}